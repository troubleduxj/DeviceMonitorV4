# Phase 4: AIé›†æˆä¸ä¼˜åŒ– - å®æ–½æŒ‡å—

> **å®æ–½é˜¶æ®µ**: Phase 4 (ç¬¬10-12å‘¨)  
> **é¢„è®¡æ—¶é—´**: 2-3å‘¨  
> **å½“å‰çŠ¶æ€**: â¸ï¸ å¾…å¼€å§‹  
> **å‰ç½®æ¡ä»¶**: âœ… Phase 1-3 å·²å®Œæˆ

---

## ğŸ“‹ é˜¶æ®µæ¦‚è§ˆ

### æ ¸å¿ƒç›®æ ‡
å®ç°AIç‰¹å¾æå–æœåŠ¡ï¼Œä¸ºæœºå™¨å­¦ä¹ æ¨¡å‹æä¾›æ ‡å‡†åŒ–çš„ç‰¹å¾æ•°æ®ï¼Œå¹¶å¯¹æ•´ä¸ªç³»ç»Ÿè¿›è¡Œæ€§èƒ½ä¼˜åŒ–ã€‚

### ä¸»è¦äº¤ä»˜ç‰©
1. âœ¨ **AIç‰¹å¾æå–æœåŠ¡** - ä»æ—¶åºæ•°æ®æå–æ ‡å‡†åŒ–ç‰¹å¾
2. ğŸ“Š **è®­ç»ƒæ•°æ®é›†ç”Ÿæˆ** - ä¸ºæ¨¡å‹è®­ç»ƒå‡†å¤‡æ•°æ®
3. âš¡ **ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–** - SQLã€ç¼“å­˜ã€ç›‘æ§å…¨é¢ä¼˜åŒ–
4. ğŸ“ˆ **ç›‘æ§å‘Šè­¦é…ç½®** - Prometheus + Grafanaä»ªè¡¨ç›˜

---

## ğŸ¯ Week 10-11: AIç‰¹å¾æå–æœåŠ¡å¼€å‘

### ç›®æ ‡
å¼€å‘å®Œæ•´çš„AIç‰¹å¾æå–æœåŠ¡ï¼Œæ”¯æŒå¤šç§ç‰¹å¾å·¥ç¨‹æ–¹æ³•

---

### Day 1-3: AIFeatureService æ ¸å¿ƒå¼€å‘

#### ä»»åŠ¡ 4.1: åˆ›å»º AIFeatureService ç±»

**æ–‡ä»¶**: `app/services/ai_feature_service.py`  
**é¢„è®¡ä»£ç é‡**: 600-800è¡Œ

**æ ¸å¿ƒæ–¹æ³•**:

```python
class AIFeatureService:
    """AIç‰¹å¾æå–æœåŠ¡"""
    
    async def extract_features(
        self,
        model_code: str,
        device_code: str,
        start_time: datetime,
        end_time: datetime,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æå–ç‰¹å¾çŸ©é˜µ
        
        å‚æ•°:
            model_code: æ•°æ®æ¨¡å‹ä»£ç 
            device_code: è®¾å¤‡ç¼–ç 
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚window_size, normalize_methodç­‰ï¼‰
        
        è¿”å›:
            {
                "features": [...],  # ç‰¹å¾çŸ©é˜µ
                "feature_names": [...],  # ç‰¹å¾åç§°
                "timestamps": [...],  # æ—¶é—´æˆ³
                "metadata": {...}  # å…ƒæ•°æ®
            }
        """
        pass
    
    def _handle_missing_values(
        self,
        data: pd.DataFrame,
        method: str = 'interpolate'
    ) -> pd.DataFrame:
        """
        å¤„ç†ç¼ºå¤±å€¼
        
        æ–¹æ³•:
            - 'drop': åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
            - 'forward_fill': å‰å‘å¡«å……
            - 'backward_fill': åå‘å¡«å……
            - 'interpolate': çº¿æ€§æ’å€¼
            - 'mean': å‡å€¼å¡«å……
            - 'median': ä¸­ä½æ•°å¡«å……
        """
        pass
    
    def _handle_outliers(
        self,
        data: pd.DataFrame,
        method: str = 'iqr',
        threshold: float = 1.5
    ) -> pd.DataFrame:
        """
        å¤„ç†å¼‚å¸¸å€¼
        
        æ–¹æ³•:
            - 'iqr': IQRæ–¹æ³•ï¼ˆå››åˆ†ä½è·ï¼‰
            - 'z_score': Z-Scoreæ–¹æ³•
            - 'clip': æˆªæ–­æ³•
        """
        pass
    
    def _apply_sliding_window(
        self,
        data: pd.DataFrame,
        window_size: int,
        overlap: float = 0.5
    ) -> List[pd.DataFrame]:
        """
        åº”ç”¨æ»‘åŠ¨çª—å£
        
        å‚æ•°:
            window_size: çª—å£å¤§å°ï¼ˆæ•°æ®ç‚¹æ•°é‡ï¼‰
            overlap: é‡å æ¯”ä¾‹ï¼ˆ0-1ä¹‹é—´ï¼‰
        
        è¿”å›:
            çª—å£åŒ–çš„æ•°æ®ç‰‡æ®µåˆ—è¡¨
        """
        pass
    
    def _min_max_normalize(
        self,
        data: pd.DataFrame,
        feature_range: Tuple[float, float] = (0, 1)
    ) -> pd.DataFrame:
        """
        Min-Maxå½’ä¸€åŒ–
        
        å…¬å¼: (x - min) / (max - min) * (max' - min') + min'
        """
        pass
    
    def _z_score_normalize(
        self,
        data: pd.DataFrame
    ) -> pd.DataFrame:
        """
        Z-Scoreæ ‡å‡†åŒ–
        
        å…¬å¼: (x - mean) / std
        """
        pass
    
    async def generate_training_dataset(
        self,
        model_code: str,
        device_codes: List[str],
        start_time: datetime,
        end_time: datetime,
        label_column: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆè®­ç»ƒæ•°æ®é›†
        
        è¿”å›:
            {
                "X_train": [...],  # è®­ç»ƒç‰¹å¾
                "y_train": [...],  # è®­ç»ƒæ ‡ç­¾
                "X_val": [...],    # éªŒè¯ç‰¹å¾
                "y_val": [...],    # éªŒè¯æ ‡ç­¾
                "feature_info": {...}  # ç‰¹å¾ä¿¡æ¯
            }
        """
        pass
```

**æŠ€æœ¯æ ˆ**:
- NumPy - æ•°å€¼è®¡ç®—
- Pandas - æ•°æ®å¤„ç†
- Scikit-learn - ç‰¹å¾å·¥ç¨‹
- TDengine - æ—¶åºæ•°æ®æŸ¥è¯¢

**ä¾èµ–å…³ç³»**:
```python
# requirements.txt æ–°å¢
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
```

**éªŒæ”¶æ ‡å‡†**:
- [x] æ”¯æŒ6ç§ç¼ºå¤±å€¼å¤„ç†æ–¹æ³•
- [x] æ”¯æŒ3ç§å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•
- [x] æ”¯æŒæ»‘åŠ¨çª—å£ï¼ˆå¯é…ç½®çª—å£å¤§å°å’Œé‡å ï¼‰
- [x] æ”¯æŒ2ç§å½’ä¸€åŒ–æ–¹æ³•
- [x] æ”¯æŒè®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†

---

### Day 4-5: AIç‰¹å¾APIå¼€å‘

#### ä»»åŠ¡ 4.2: åˆ›å»ºç‰¹å¾æå–API

**æ–‡ä»¶**: `app/api/v2/ai/features.py`  
**é¢„è®¡ä»£ç é‡**: 350-400è¡Œ

**APIæ¸…å•** (3ä¸ªæ¥å£):

##### 1. POST /api/v2/ai/features/extract - æå–ç‰¹å¾

**è¯·æ±‚å‚æ•°**:
```json
{
  "model_code": "welding_ai_model",
  "device_code": "WLD001",
  "start_time": "2025-11-01T00:00:00",
  "end_time": "2025-11-02T00:00:00",
  "window_size": 100,
  "overlap": 0.5,
  "normalize_method": "z_score",
  "missing_value_method": "interpolate",
  "outlier_method": "iqr"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "features": [[...], [...], ...],
    "feature_names": ["current_mean", "voltage_std", ...],
    "timestamps": ["2025-11-01T00:00:00", ...],
    "metadata": {
      "window_count": 48,
      "window_size": 100,
      "overlap": 0.5,
      "normalize_method": "z_score"
    }
  },
  "execution_time": 1250
}
```

---

##### 2. POST /api/v2/ai/features/dataset - åˆ›å»ºè®­ç»ƒæ•°æ®é›†

**è¯·æ±‚å‚æ•°**:
```json
{
  "model_code": "welding_ai_model",
  "device_codes": ["WLD001", "WLD002", "WLD003"],
  "start_time": "2025-10-01T00:00:00",
  "end_time": "2025-11-01T00:00:00",
  "label_column": "quality_label",
  "val_split": 0.2,
  "random_state": 42,
  "window_size": 100,
  "overlap": 0.5,
  "normalize_method": "min_max"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "dataset_id": "ds_20251103_001",
    "train_samples": 3840,
    "val_samples": 960,
    "feature_count": 25,
    "class_distribution": {
      "0": 2800,
      "1": 2000
    },
    "download_url": "/api/v2/ai/datasets/ds_20251103_001/download"
  }
}
```

---

##### 3. GET /api/v2/ai/features/stats - ç‰¹å¾ç»Ÿè®¡

**è¯·æ±‚å‚æ•°**:
```
GET /api/v2/ai/features/stats?model_code=welding_ai_model&start_time=...&end_time=...
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "feature_statistics": [
      {
        "feature_name": "current_mean",
        "min": 120.5,
        "max": 180.3,
        "mean": 150.2,
        "std": 12.5,
        "missing_ratio": 0.02
      },
      ...
    ],
    "correlation_matrix": [[...], [...], ...],
    "sample_count": 10000
  }
}
```

---

#### ä»»åŠ¡ 4.3: APIæ³¨å†Œä¸æµ‹è¯•

**ä¿®æ”¹æ–‡ä»¶**: `app/api/v2/__init__.py`

```python
# æ·»åŠ  AIç‰¹å¾è·¯ç”±
from app.api.v2.ai.features import router as ai_features_router

v2_router.include_router(
    ai_features_router,
    prefix="/ai/features",
    tags=["AIç‰¹å¾æå– v2"]
)
```

**æµ‹è¯•æ¸…å•**:
- [ ] å•è®¾å¤‡ç‰¹å¾æå–æµ‹è¯•
- [ ] å¤šè®¾å¤‡æ•°æ®é›†ç”Ÿæˆæµ‹è¯•
- [ ] ç‰¹å¾ç»Ÿè®¡æŸ¥è¯¢æµ‹è¯•
- [ ] é”™è¯¯å¤„ç†æµ‹è¯•ï¼ˆæ— æ•ˆå‚æ•°ã€æ•°æ®ä¸è¶³ç­‰ï¼‰
- [ ] æ€§èƒ½æµ‹è¯•ï¼ˆ> 1000æ¡/ç§’ï¼‰

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ‰€æœ‰APIæ¥å£æ­£å¸¸å·¥ä½œ
- [ ] å“åº”æ ¼å¼ç¬¦åˆAPI V2è§„èŒƒ
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] Swaggeræ–‡æ¡£å®Œæ•´
- [ ] æ€§èƒ½è¾¾æ ‡ï¼ˆç‰¹å¾æå– > 1000æ¡/ç§’ï¼‰

---

## âš¡ Week 12: ç³»ç»Ÿä¼˜åŒ–

### ç›®æ ‡
å…¨é¢ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œå»ºç«‹ç›‘æ§å‘Šè­¦ä½“ç³»

---

### Day 1-2: æ€§èƒ½ä¼˜åŒ–

#### ä»»åŠ¡ 12.1: SQLæŸ¥è¯¢ä¼˜åŒ–

**ä¼˜åŒ–é¡¹**:

1. **ç´¢å¼•ä¼˜åŒ–**
```sql
-- åˆ†ææ…¢æŸ¥è¯¢
SELECT * FROM pg_stat_statements 
ORDER BY total_exec_time DESC 
LIMIT 10;

-- æ·»åŠ å¤åˆç´¢å¼•
CREATE INDEX idx_device_field_type_code 
ON t_device_field (device_type_id, field_code);

CREATE INDEX idx_data_model_type_status 
ON t_device_data_model (model_type, is_active);

-- æ·»åŠ éƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_active_models 
ON t_device_data_model (model_code) 
WHERE is_active = true;
```

2. **æŸ¥è¯¢é‡å†™**
```python
# Before: N+1æŸ¥è¯¢
models = await DeviceDataModel.all()
for model in models:
    mappings = await model.field_mappings.all()  # Næ¬¡æŸ¥è¯¢

# After: é¢„åŠ è½½
models = await DeviceDataModel.all().prefetch_related('field_mappings')
for model in models:
    mappings = model.field_mappings  # 0æ¬¡æŸ¥è¯¢
```

3. **åˆ†é¡µä¼˜åŒ–**
```python
# Before: COUNT(*)å¾ˆæ…¢
total = await DeviceDataModel.all().count()
models = await DeviceDataModel.all().offset(skip).limit(limit)

# After: ä½¿ç”¨approximate count
total = await get_approximate_count('t_device_data_model')
models = await DeviceDataModel.all().offset(skip).limit(limit)
```

---

#### ä»»åŠ¡ 12.2: ç¼“å­˜ä¼˜åŒ–

**ä¼˜åŒ–ç­–ç•¥**:

1. **æŸ¥è¯¢ç»“æœç¼“å­˜**
```python
from functools import lru_cache
from app.core.cache import redis_client

# æ¨¡å‹é…ç½®ç¼“å­˜ï¼ˆ24å°æ—¶ï¼‰
@lru_cache(maxsize=100)
async def get_cached_model_config(model_code: str):
    cache_key = f"model:config:{model_code}"
    cached = await redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    
    config = await get_model_config(model_code)
    await redis_client.set(cache_key, json.dumps(config), ex=86400)
    return config

# å­—æ®µæ˜ å°„ç¼“å­˜ï¼ˆ6å°æ—¶ï¼‰
async def get_cached_field_mappings(device_type_id: int):
    cache_key = f"mappings:{device_type_id}"
    # ... ç±»ä¼¼é€»è¾‘
```

2. **ç¼“å­˜é¢„çƒ­**
```python
# app/core/init_app.py
async def warm_up_cache():
    """åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­ç¼“å­˜"""
    logger.info("å¼€å§‹ç¼“å­˜é¢„çƒ­...")
    
    # é¢„çƒ­æ´»è·ƒæ¨¡å‹é…ç½®
    active_models = await DeviceDataModel.filter(is_active=True).all()
    for model in active_models:
        await get_cached_model_config(model.model_code)
    
    # é¢„çƒ­å­—æ®µæ˜ å°„
    device_types = await DeviceType.all()
    for dt in device_types:
        await get_cached_field_mappings(dt.id)
    
    logger.info(f"ç¼“å­˜é¢„çƒ­å®Œæˆï¼Œå…±é¢„çƒ­ {len(active_models)} ä¸ªæ¨¡å‹")
```

3. **ç¼“å­˜å¤±æ•ˆç­–ç•¥**
```python
# æ¨¡å‹æ›´æ–°æ—¶æ¸…é™¤ç¼“å­˜
async def update_model(model_id: int, data: dict):
    model = await DeviceDataModel.get(id=model_id)
    
    # æ›´æ–°æ¨¡å‹
    await model.update_from_dict(data)
    await model.save()
    
    # æ¸…é™¤ç›¸å…³ç¼“å­˜
    cache_key = f"model:config:{model.model_code}"
    await redis_client.delete(cache_key)
    get_cached_model_config.cache_clear()  # æ¸…é™¤LRUç¼“å­˜
    
    return model
```

**æ€§èƒ½ç›®æ ‡**:
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 95%
- [ ] ç¼“å­˜å“åº”æ—¶é—´ < 10ms
- [ ] æŸ¥è¯¢æ€§èƒ½æå‡ > 50%

---

### Day 3-4: ç›‘æ§å‘Šè­¦é…ç½®

#### ä»»åŠ¡ 12.3: Prometheusç›‘æ§

**1. Prometheusé…ç½®**

**æ–‡ä»¶**: `prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'device-monitor-api'
    static_configs:
      - targets: ['localhost:8001']
    metrics_path: '/api/v2/metrics'
```

**2. FastAPI Metricsä¸­é—´ä»¶**

**æ–‡ä»¶**: `app/core/middlewares.py`

```python
from prometheus_client import Counter, Histogram, Gauge
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

# å®šä¹‰æŒ‡æ ‡
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

http_request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

active_queries = Gauge(
    'active_queries',
    'Number of active database queries'
)

# æ·»åŠ Metricsç«¯ç‚¹
@router.get("/metrics")
async def metrics():
    return Response(
        generate_latest(),
        media_type=CONTENT_TYPE_LATEST
    )
```

**3. è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡**

```python
# app/services/metrics.py
from prometheus_client import Gauge, Counter

# æ¨¡å‹ç›¸å…³æŒ‡æ ‡
model_query_count = Counter(
    'model_query_total',
    'Total model queries',
    ['model_code', 'model_type']
)

model_query_duration = Histogram(
    'model_query_duration_seconds',
    'Model query duration',
    ['model_code']
)

feature_extraction_count = Counter(
    'feature_extraction_total',
    'Total feature extractions',
    ['model_code']
)

# åœ¨ä¸šåŠ¡ä»£ç ä¸­ä½¿ç”¨
async def query_realtime_data(model_code: str, ...):
    start_time = time.time()
    
    try:
        result = await _do_query(...)
        model_query_count.labels(
            model_code=model_code,
            model_type='realtime'
        ).inc()
        
        return result
    finally:
        duration = time.time() - start_time
        model_query_duration.labels(model_code=model_code).observe(duration)
```

---

#### ä»»åŠ¡ 12.4: Grafanaä»ªè¡¨ç›˜

**Grafanaé…ç½®**:

1. **APIæ€§èƒ½ä»ªè¡¨ç›˜**
   - HTTPè¯·æ±‚é‡ï¼ˆQPSï¼‰
   - å“åº”æ—¶é—´ï¼ˆP50/P90/P99ï¼‰
   - é”™è¯¯ç‡
   - æ´»è·ƒè¿æ¥æ•°

2. **æ•°æ®åº“æ€§èƒ½ä»ªè¡¨ç›˜**
   - æŸ¥è¯¢TPS
   - æ…¢æŸ¥è¯¢æ•°é‡
   - è¿æ¥æ± ä½¿ç”¨ç‡
   - ç¼“å­˜å‘½ä¸­ç‡

3. **ä¸šåŠ¡æŒ‡æ ‡ä»ªè¡¨ç›˜**
   - æ¨¡å‹æŸ¥è¯¢é‡ï¼ˆæŒ‰æ¨¡å‹ç±»å‹ï¼‰
   - ç‰¹å¾æå–é‡
   - æ•°æ®å¤„ç†è€—æ—¶
   - æ´»è·ƒè®¾å¤‡æ•°

**Grafana Dashboard JSON**:

```json
{
  "dashboard": {
    "title": "Device Monitor - æ•°æ®æ¨¡å‹æ€§èƒ½",
    "panels": [
      {
        "title": "API QPS",
        "targets": [
          {
            "expr": "rate(http_requests_total[1m])"
          }
        ]
      },
      {
        "title": "æ¨¡å‹æŸ¥è¯¢é‡ Top 10",
        "targets": [
          {
            "expr": "topk(10, sum by (model_code) (rate(model_query_total[5m])))"
          }
        ]
      }
    ]
  }
}
```

**å‘Šè­¦è§„åˆ™**:

```yaml
groups:
  - name: device_monitor_alerts
    rules:
      - alert: HighAPILatency
        expr: http_request_duration_seconds{quantile="0.99"} > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "APIå“åº”æ—¶é—´è¿‡é•¿"
          description: "P99å»¶è¿Ÿè¶…è¿‡2ç§’"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "APIé”™è¯¯ç‡è¿‡é«˜"
          description: "5xxé”™è¯¯ç‡è¶…è¿‡5%"
      
      - alert: LowCacheHitRate
        expr: cache_hit_rate < 0.9
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½"
          description: "ç¼“å­˜å‘½ä¸­ç‡ä½äº90%"
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] Prometheusæ­£ç¡®é‡‡é›†æŒ‡æ ‡
- [ ] Grafanaä»ªè¡¨ç›˜æ­£å¸¸æ˜¾ç¤º
- [ ] å‘Šè­¦è§„åˆ™é…ç½®å®Œæˆ
- [ ] å‘Šè­¦é€šçŸ¥æ­£å¸¸ï¼ˆé‚®ä»¶/é’‰é’‰/ä¼ä¸šå¾®ä¿¡ï¼‰

---

### Day 5: æ–‡æ¡£ä¸æµ‹è¯•

#### ä»»åŠ¡ 12.5: æ€§èƒ½æµ‹è¯•

**æµ‹è¯•å·¥å…·**: Locust

**æµ‹è¯•è„šæœ¬**: `tests/performance/locustfile.py`

```python
from locust import HttpUser, task, between

class DataModelUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        # ç™»å½•è·å–token
        response = self.client.post("/api/v2/auth/login", json={
            "username": "test_user",
            "password": "test_pass"
        })
        self.token = response.json()["data"]["access_token"]
    
    @task(3)
    def query_models(self):
        self.client.get(
            "/api/v2/metadata/models",
            headers={"Authorization": f"Bearer {self.token}"}
        )
    
    @task(2)
    def query_data(self):
        self.client.post(
            "/api/v2/data/query/realtime",
            json={
                "model_code": "welding_realtime",
                "filters": {},
                "page": 1,
                "page_size": 50
            },
            headers={"Authorization": f"Bearer {self.token}"}
        )
    
    @task(1)
    def extract_features(self):
        self.client.post(
            "/api/v2/ai/features/extract",
            json={
                "model_code": "welding_ai_model",
                "device_code": "WLD001",
                "start_time": "2025-11-01T00:00:00",
                "end_time": "2025-11-01T01:00:00"
            },
            headers={"Authorization": f"Bearer {self.token}"}
        )
```

**æ‰§è¡Œæµ‹è¯•**:
```bash
# 100å¹¶å‘ï¼ŒæŒç»­5åˆ†é’Ÿ
locust -f tests/performance/locustfile.py \
  --host=http://localhost:8001 \
  --users=100 \
  --spawn-rate=10 \
  --run-time=5m
```

**æ€§èƒ½æŒ‡æ ‡**:
| æŒ‡æ ‡ | ç›®æ ‡ | å®é™… | çŠ¶æ€ |
|------|------|------|------|
| QPS | > 100 | ? | â¸ï¸ å¾…æµ‹è¯• |
| P99å»¶è¿Ÿ | < 2s | ? | â¸ï¸ å¾…æµ‹è¯• |
| é”™è¯¯ç‡ | < 1% | ? | â¸ï¸ å¾…æµ‹è¯• |
| ç¼“å­˜å‘½ä¸­ç‡ | > 95% | ? | â¸ï¸ å¾…æµ‹è¯• |

---

#### ä»»åŠ¡ 12.6: æ–‡æ¡£æ›´æ–°

**éœ€æ›´æ–°çš„æ–‡æ¡£**:

1. **APIæ¥å£æ–‡æ¡£**
   - æ·»åŠ 3ä¸ªAIç‰¹å¾APIæ–‡æ¡£
   - æ›´æ–°æ€§èƒ½æŒ‡æ ‡è¯´æ˜

2. **éƒ¨ç½²æ–‡æ¡£**
   - æ·»åŠ Prometheuséƒ¨ç½²æ­¥éª¤
   - æ·»åŠ Grafanaé…ç½®è¯´æ˜

3. **æ€§èƒ½è°ƒä¼˜æŒ‡å—**
   - SQLä¼˜åŒ–å»ºè®®
   - ç¼“å­˜é…ç½®å»ºè®®
   - ç›‘æ§å‘Šè­¦é…ç½®

---

## ğŸ“Š Phase 4 äº¤ä»˜æˆæœ

### ä»£ç äº¤ä»˜
- âœ¨ `AIFeatureService` ç±»ï¼ˆ600-800è¡Œï¼‰
- âœ¨ 3ä¸ªAIç‰¹å¾APIæ¥å£ï¼ˆ350-400è¡Œï¼‰
- âš¡ SQLä¼˜åŒ–è„šæœ¬
- âš¡ ç¼“å­˜é…ç½®ä»£ç 
- ğŸ“ˆ Prometheus + Grafanaé…ç½®

### æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ç›®æ ‡ | éªŒè¯ |
|------|--------|------|------|
| API QPS | ~50 | > 100 | â¸ï¸ |
| P99å»¶è¿Ÿ | ~3s | < 2s | â¸ï¸ |
| ç¼“å­˜å‘½ä¸­ç‡ | ~70% | > 95% | â¸ï¸ |
| ç‰¹å¾æå–æ€§èƒ½ | - | > 1000æ¡/ç§’ | â¸ï¸ |

### æ–‡æ¡£äº¤ä»˜
- ğŸ“„ Phase 4å®ŒæˆæŠ¥å‘Š
- ğŸ“„ AIç‰¹å¾æå–APIæ–‡æ¡£
- ğŸ“„ æ€§èƒ½è°ƒä¼˜æŒ‡å—
- ğŸ“„ ç›‘æ§é…ç½®æ‰‹å†Œ

---

## ğŸ¯ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] AIç‰¹å¾æå–æœåŠ¡æ­£å¸¸å·¥ä½œ
- [ ] æ”¯æŒ6ç§ç¼ºå¤±å€¼å¤„ç†æ–¹æ³•
- [ ] æ”¯æŒ3ç§å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•
- [ ] æ”¯æŒ2ç§å½’ä¸€åŒ–æ–¹æ³•
- [ ] è®­ç»ƒæ•°æ®é›†ç”ŸæˆåŠŸèƒ½æ­£å¸¸

### æ€§èƒ½éªŒæ”¶
- [ ] ç‰¹å¾æå–æ€§èƒ½ > 1000æ¡/ç§’
- [ ] API QPS > 100
- [ ] P99å»¶è¿Ÿ < 2ç§’
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 95%
- [ ] é”™è¯¯ç‡ < 1%

### ç›‘æ§éªŒæ”¶
- [ ] Prometheusæ­£ç¡®é‡‡é›†æŒ‡æ ‡
- [ ] Grafanaä»ªè¡¨ç›˜æ­£å¸¸æ˜¾ç¤º
- [ ] å‘Šè­¦è§„åˆ™é…ç½®å®Œæˆ
- [ ] å‘Šè­¦é€šçŸ¥æ­£å¸¸

### æ–‡æ¡£éªŒæ”¶
- [ ] APIæ–‡æ¡£å®Œæ•´
- [ ] æ€§èƒ½è°ƒä¼˜æŒ‡å—å®Œæ•´
- [ ] ç›‘æ§é…ç½®æ‰‹å†Œå®Œæ•´
- [ ] Phase 4å®ŒæˆæŠ¥å‘Šå®Œæ•´

---

## âš ï¸ é£é™©ä¸åº”å¯¹

| é£é™© | æ¦‚ç‡ | å½±å“ | åº”å¯¹æªæ–½ |
|------|------|------|----------|
| AIç®—æ³•å¤æ‚åº¦é«˜ | ä¸­ | é«˜ | å…ˆå®ç°åŸºç¡€åŠŸèƒ½ï¼Œé«˜çº§åŠŸèƒ½è¿­ä»£ |
| æ€§èƒ½ç›®æ ‡éš¾ä»¥è¾¾æˆ | ä¸­ | ä¸­ | åˆ†é˜¶æ®µä¼˜åŒ–ï¼ŒæŒç»­æ”¹è¿› |
| Redisä¾èµ–é—®é¢˜ | ä½ | ä¸­ | æ”¯æŒé™çº§åˆ°å†…å­˜ç¼“å­˜ |
| ç›‘æ§é…ç½®å¤æ‚ | ä¸­ | ä½ | æä¾›é…ç½®æ¨¡æ¿å’Œç¤ºä¾‹ |

---

## ğŸ“… æ—¶é—´è§„åˆ’

### Week 10
- Day 1-3: AIFeatureServiceæ ¸å¿ƒå¼€å‘
- Day 4-5: AIç‰¹å¾APIå¼€å‘

### Week 11
- Day 1-2: é›†æˆæµ‹è¯•å’Œè°ƒè¯•
- Day 3-5: æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

### Week 12
- Day 1-2: æ€§èƒ½ä¼˜åŒ–
- Day 3-4: ç›‘æ§å‘Šè­¦é…ç½®
- Day 5: æµ‹è¯•å’Œæ–‡æ¡£

---

## ğŸ‰ å®Œæˆå

Phase 4å®Œæˆåï¼Œç³»ç»Ÿå°†å…·å¤‡ï¼š
1. âœ¨ **å®Œæ•´çš„AIèƒ½åŠ›** - ç‰¹å¾æå–ã€æ•°æ®é›†ç”Ÿæˆ
2. âš¡ **ä¼˜ç§€çš„æ€§èƒ½** - QPSç¿»å€ï¼Œå»¶è¿Ÿå‡åŠ
3. ğŸ“ˆ **å®Œå–„çš„ç›‘æ§** - å®æ—¶æŒæ¡ç³»ç»ŸçŠ¶æ€
4. ğŸ›¡ï¸ **ç¨³å®šçš„è¿è¡Œ** - å‘Šè­¦åŠæ—¶ï¼Œå¿«é€Ÿå“åº”

**ä¸‹ä¸€æ­¥**: Phase 5 - å…¨é¢æµ‹è¯•ä¸æ­£å¼ä¸Šçº¿

---

**åˆ›å»ºæ—¶é—´**: 2025-11-03  
**ä½œè€…**: AI Assistant  
**çŠ¶æ€**: â¸ï¸ å¾…å¼€å§‹


